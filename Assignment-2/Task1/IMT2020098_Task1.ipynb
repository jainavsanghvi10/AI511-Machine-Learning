{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_NAME = 'Jainav Sanghvi' #Put your name\n",
    "STUDENT_ROLLNO = 'IMT2020098' #Put your roll number\n",
    "CODE_COMPLETE = True\n",
    "# set the above to True if you were able to complete the code\n",
    "# and that you feel your model can generate a good result\n",
    "# otherwise keep it as False\n",
    "# Don't lie about this. This is so that we don't waste time with\n",
    "# the autograder and just perform a manual check\n",
    "# If the flag above is True and your code crashes, that's\n",
    "# an instant deduction of 2 points on the assignment.\n",
    "#\n",
    "#@PROTECTED_1_BEGIN\n",
    "## No code within \"PROTECTED\" can be modified.\n",
    "## We expect this part to be VERBATIM.\n",
    "## IMPORTS \n",
    "## No other library imports other than the below are allowed.\n",
    "## No, not even Scipy\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn.model_selection as model_selection \n",
    "import sklearn.preprocessing as preprocessing \n",
    "import sklearn.metrics as metrics \n",
    "from tqdm import tqdm # You can make lovely progress bars using this\n",
    "\n",
    "## FILE READING: \n",
    "## You are not permitted to read any files other than the ones given below.\n",
    "X_train = pd.read_csv(\"train_X.csv\",index_col=0).to_numpy()\n",
    "y_train = pd.read_csv(\"train_y.csv\",index_col=0).to_numpy().reshape(-1,)\n",
    "X_test = pd.read_csv(\"test_X.csv\",index_col=0).to_numpy()\n",
    "submissions_df = pd.read_csv(\"sample_submission.csv\",index_col=0)\n",
    "mnist_test = pd.read_csv(\"mnist_test.csv\")\n",
    "#@PROTECTED_1_END\n",
    "\n",
    "y_test = mnist_test['label']\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "y_test = y_test.to_numpy().reshape(-1,)\n",
    "\n",
    "mnist_test = mnist_test.drop(['label'], axis=1)\n",
    "mnist_test.reset_index(drop=True,inplace=True)\n",
    "mnist_test = mnist_test.to_numpy()\n",
    "\n",
    "def OneHEncoding(y):\n",
    "    temp = np.zeros((y.shape[0], 10))\n",
    "    for i in range(y.shape[0]):\n",
    "        temp[i][int(y[i])] = 1 \n",
    "    return temp\n",
    "\n",
    "y_train=OneHEncoding(y_train)\n",
    "y_test=OneHEncoding(y_test)\n",
    "\n",
    "def normalization(X):\n",
    "    X=X/255\n",
    "    return X\n",
    "\n",
    "X_train=normalization(X_train)\n",
    "X_test=normalization(X_test)\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def dReLU(x):\n",
    "    return x > 0\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis = 1).reshape(z.shape[0],1)\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis = 1).reshape(z.shape[0],1)\n",
    "    \n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(np.dot(-1, Z)))\n",
    "    return A\n",
    "# layer_dims holds the dimensions of each layer\n",
    "def InitializeParameters(layer_dims):\n",
    "    np.random.seed(10)\n",
    "    params = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(0, L-1): #0 to 2\n",
    "        params['W'+str(l+1)] = np.random.randn(layer_dims[l], layer_dims[l+1])\n",
    "        params['b'+str(l+1)] = np.random.randn(layer_dims[l+1],)      \n",
    "    return params\n",
    "\n",
    "def shuffleData(X, Y):\n",
    "    i = [j for j in range(X.shape[0])]\n",
    "    np.random.seed(10)\n",
    "    np.random.shuffle(i)\n",
    "    X = X[i]\n",
    "    Y = Y[i]\n",
    "    return X, Y\n",
    "\n",
    "def forwardPropogation(X,params):\n",
    "    A = X # input to first layer i.e. training data\n",
    "    input = []\n",
    "    output = []\n",
    "    L = len(params)//2\n",
    "    for l in range(1, L+1):\n",
    "        A_prev = A\n",
    "        # Linear Hypothesis\n",
    "        Z = np.dot(A_prev,params['W'+str(l)]) + params['b'+str(l)] \n",
    "        input.append(Z)\n",
    "        # Applying activation function on linear hypothesis\n",
    "        if l==L: A= softmax(Z) \n",
    "        else: A= ReLU(Z) \n",
    "        output.append(A)   \n",
    "    return input,output\n",
    "\n",
    "def backPropogation(X, Y,input,output, params, bSize, learning_rate):\n",
    "    error = output[2] - Y\n",
    "    dCost = (error)/bSize\n",
    "    dW3 = np.dot(dCost.T,output[1]).T\n",
    "    dW2 = np.dot((np.dot((dCost),params['W3'].T) * dReLU(input[1])).T,output[0]).T\n",
    "    dW1 = np.dot((np.dot(np.dot((dCost),params['W3'].T)*dReLU(input[1]), params['W2'].T)*dReLU(input[0])).T,X).T   \n",
    "    db3 = np.sum(dCost,axis = 0)\n",
    "    db2 = np.sum(np.dot((dCost),params['W3'].T) * dReLU(input[1]),axis = 0)\n",
    "    db1 = np.sum((np.dot(np.dot((dCost),params['W3'].T)*dReLU(input[1]),params['W2'].T)*dReLU(input[0])),axis = 0)   \n",
    "    #Now applying SGD \n",
    "    params['W3'] -= learning_rate*dW3\n",
    "    params['W2'] -= learning_rate*dW2\n",
    "    params['W1'] -= learning_rate*dW1   \n",
    "    params['b3'] -= learning_rate*db3\n",
    "    params['b2'] -= learning_rate*db2\n",
    "    params['b1'] -= learning_rate*db1\n",
    "    return params\n",
    "\n",
    "def train(X, y, layer_dims, lr):\n",
    "    params = InitializeParameters(layer_dims)\n",
    "    cost_history = []\n",
    "    accuracy_history = []\n",
    "    bSize=64\n",
    "    learning_rate=lr\n",
    "\n",
    "    Xn = X[:bSize] # batch input \n",
    "    yn = y[:bSize] # batch target value\n",
    "    for i in range(20):\n",
    "        X, y = shuffleData(X, y)\n",
    "        cost = 0\n",
    "        accuracy = 0\n",
    "        for index in range(X.shape[0]//bSize-1):\n",
    "            s = index*bSize\n",
    "            e = (index+1)*bSize\n",
    "            Xn = X[s:e]\n",
    "            yn = y[s:e]\n",
    "            input,output = forwardPropogation(Xn,params)\n",
    "            params = backPropogation(Xn, yn,input,output,params, bSize, learning_rate)\n",
    "            error = output[2] - yn\n",
    "            cost+=np.mean(error**2)\n",
    "            accuracy+= np.count_nonzero(np.argmax(output[2],axis=1) == np.argmax(yn,axis=1)) / bSize\n",
    "        cost_history.append(cost/(X.shape[0]//bSize))\n",
    "        accuracy_history.append(accuracy*100/(X.shape[0]//bSize))\n",
    "    return params\n",
    "\n",
    "params=train(X_train,y_train,[784,512,512,10],0.005)\n",
    "\n",
    "def test(X_test,y_test,mnist_test,params):\n",
    "    mnist_test = normalization(mnist_test)\n",
    "    X_test = normalization(X_test)\n",
    "    \n",
    "    input,output = forwardPropogation(mnist_test,params)\n",
    "    accuracy = np.count_nonzero(np.argmax(output[2],axis=1)==np.argmax(y_test,axis=1)) / mnist_test.shape[0]\n",
    "    print(\"Total Accuracy = \", 100 * accuracy, \"%\")\n",
    "    \n",
    "    input,output = forwardPropogation(X_test,params)\n",
    "    out = np.zeros((output[2].shape[0],))\n",
    "   \n",
    "    for i in range(out.shape[0]):\n",
    "        out[i] = np.argmax(output[2][i])\n",
    "    res_df = pd.DataFrame(out, columns = ['label'])\n",
    "    return res_df    \n",
    "\n",
    "submissions_df = test(X_test,y_test,mnist_test,params)\n",
    "\n",
    "#@PROTECTED_2_BEGIN \n",
    "##FILE WRITING:\n",
    "# You are not permitted to write to any file other than the one given below.\n",
    "submissions_df.to_csv(\"{}__{}.csv\".format(STUDENT_ROLLNO,STUDENT_NAME))\n",
    "#@PROTECTED_2_END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
